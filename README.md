# ğŸ§  LangChain + LangGraph Sandbox

A hands-on playground for learning how [LangChain](https://python.langchain.com) and [LangGraph](https://www.langchain.com/langgraph) work together to build intelligent, tool-using pipelines and graph-based agent workflows.

---

## ğŸ“‚ Project layout

```text
lcg-sandbox/
â”‚
â”œâ”€â”€ exercises/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm_provider.py             â† LLM switcher (Groq / OpenAI)
â”‚   â”œâ”€â”€ ex1_hello_langchain.py      â† minimal LangChain prompt
â”‚   â”œâ”€â”€ ex2_router_with_tool.py     â† branching logic + calculator tool
â”‚   â””â”€â”€ ex3_langgraph_router.py     â† LangGraph state machine router
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Makefile                        â† reproducible commands
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup

### 1ï¸âƒ£ Clone & enter the repo
```bash
git clone https://github.com/yourname/lcg-sandbox.git
cd lcg-sandbox
```

### 2ï¸âƒ£ Create a Python 3.11 virtual environment
```bash
python3.11 -m venv .venv311
source .venv311/bin/activate
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install -U pip
pip install -r requirements.txt
```

### 4ï¸âƒ£ Create your `.env` file

#### â¤ Using **Groq** (recommended for free usage)
```bash
PROVIDER=groq
GROQ_API_KEY=sk_your_groq_key_here
GROQ_MODEL=llama-3.1-8b-instant
```

Get a free key at [https://console.groq.com/keys](https://console.groq.com/keys).

#### â¤ Using **OpenAI**
```bash
PROVIDER=openai
OPENAI_API_KEY=sk_your_openai_key_here
OPENAI_MODEL=gpt-4o-mini
```

### 5ï¸âƒ£ Load environment variables
```bash
export $(cat .env | xargs)
```

---

## ğŸš€ Run the exercises

| Command | Description |
|----------|-------------|
| `make check` | Verify LangChain + LangGraph installation |
| `make run1` | Basic prompt with the selected LLM |
| `make run2` | Router that switches between a calculator tool and the LLM |
| `make run3` | Same logic implemented as a LangGraph state graph |
| `make clean` | Remove venv and caches |

Example:
```bash
make run1
```

Output:
```
An API ... is a set of rules that allows software systems to communicate...
```

---

## ğŸ§© How it works

- **`llm_provider.py`** â€” abstracts the choice of model (Groq or OpenAI)  
- **`ex1_hello_langchain.py`** â€” builds a simple `ChatPromptTemplate â†’ ChatModel` chain  
- **`ex2_router_with_tool.py`** â€” introduces branching logic using `RunnableBranch` and a custom calculator tool  
- **`ex3_langgraph_router.py`** â€” implements the same routing via a **LangGraph**, showing how to design LLM â€œagentsâ€ as graphs of state transitions

---

## ğŸ’¡ Next ideas

- Add structured outputs (Pydantic models)  
- Add memory or retrieval (PDF or website ingestion)  
- Visualize your LangGraph (`graph.get_graph().draw()`)  
- Deploy a lightweight FastAPI endpoint wrapping these chains


